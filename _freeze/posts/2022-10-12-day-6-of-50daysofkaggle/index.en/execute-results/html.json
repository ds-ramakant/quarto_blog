{
  "hash": "6894a82596a8fe34d8303a367c446fcd",
  "result": {
    "markdown": "---\ntitle: \"Day 6 of #50daysofkaggle\"\nauthor: ''\ndate: \"2022-10-12\"\nslug: \"day-6-of-50daysofkaggle\"\ncategories: [kaggle]\nsubtitle: 'Classification using KNN'\nsummary: 'Classification using KNN'\nauthors: [Me]\nlastmod: \"2022-10-12T15:38:17+05:30\"\nfeatured: no\nimage: titanic.jpg\nprojects: [50daysofkaggle]\nformat:\n  html:\n    code-fold: true\n    code-block-border-left: true\n    toc: true\n---\n\n# Day 6: The Titanic Dataset\n\nProgress till date:\n\n-   Download titanic dataset and assign to `train` & `test`\n-   Rearranging the data\n-   EDA\n\nTo do today:\n\n-   write function to find share of survivors by each variable\n-   attempt to create model\n\n## Reading the data\n\nLoading the data using kaggle library and examining the top rows of relevant columns.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport requests\nimport numpy as np\nimport pandas as pd\nimport kaggle \nimport zipfile \n\nkaggle.api.authenticate()\n\nkaggle.api.competition_download_files(\"titanic\", path = \".\")\n\nzf = zipfile.ZipFile(\"titanic.zip\")\ntrain = pd.read_csv(zf.open(\"train.csv\"))\ntest = pd.read_csv(zf.open(\"test.csv\"))\n\n#Selecting only the numerical columns\nnum_col = train.select_dtypes(include=np.number).columns.tolist()\n\n#deslecting passenger ID and 'Survived' \ndel num_col[0:2] #.remove() can remove only 1 item. so for more than 1, use for loop \nselect_col = num_col\n\n#remaining columns\nstr_col= [\"Sex\", \"Embarked\", \"Survived\"]\n\n#Adding more elements into a list using `extend` and not `append`\nselect_col.extend(str_col)\n\ntrain_eda= train[train.columns.intersection(select_col)]\ntrain_eda.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nHow many columns with `na` values?\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ntrain_eda.isna().sum().sort_values()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\nSurvived      0\nPclass        0\nSex           0\nSibSp         0\nParch         0\nFare          0\nEmbarked      2\nAge         177\ndtype: int64\n```\n:::\n:::\n\n\nAlmost 177 entries in the `Age` column have no value. Calculating the median age of remaining data.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ntrain_eda[\"Age\"].median() #28\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n28.0\n```\n:::\n:::\n\n\nReplacing these with the median age (28) instead of removing them.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ntrain_eda[\"Age\"].fillna(value = train_eda[\"Age\"].median(), inplace = True)\ntrain_eda.isna().sum().sort_values()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5312\\1076914416.py:1: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nSurvived    0\nPclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nEmbarked    2\ndtype: int64\n```\n:::\n:::\n\n\nToday I want to calculate the survival rate of each of these attributes (`Pclass, Sex, Embarked`).\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf_copy2 = pd.DataFrame(columns = {\"category\", \"col\", \"survive_rate\"})\n\nfor t in [\"Pclass\", \"Sex\", \"Embarked\"]:\n  df_copy = train_eda.groupby([t])[\"Survived\"].mean().reset_index()\n  df_copy[\"category\"] = t\n  #trying to create a `tidy` version of the data \n  df_copy.rename(columns = {t: \"col\", \"Survived\": \"survive_rate\"}, errors = \"raise\", inplace = True)\n  df_copy = df_copy[[\"category\", \"col\", \"survive_rate\"]]\n  df_copy2= pd.concat([df_copy2, df_copy], ignore_index = True)\n\n\n#final table in a tidy format that can be used to create graphs. but that i'm keeping for later\ndf_copy2[[\"category\", \"col\", \"survive_rate\"]]\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>col</th>\n      <th>survive_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pclass</td>\n      <td>1</td>\n      <td>0.62963</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pclass</td>\n      <td>2</td>\n      <td>0.472826</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pclass</td>\n      <td>3</td>\n      <td>0.242363</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sex</td>\n      <td>female</td>\n      <td>0.742038</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sex</td>\n      <td>male</td>\n      <td>0.188908</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Embarked</td>\n      <td>C</td>\n      <td>0.553571</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Embarked</td>\n      <td>Q</td>\n      <td>0.38961</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Embarked</td>\n      <td>S</td>\n      <td>0.336957</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWith this, its pretty clear that among the `sex` category, males had the least likelihood of surviving with 19%. The richer `class 1` managed a 63% chance of survival while only 24% of the lower `class 3` survived. Finally those that `embarked` from Cherbourg had a higher survival rate 55% compared to Southampton at 34%.\n\n## Model building\n\nSeperating the X & y. Here's the first 5 rows of `X`\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ntrain_eda.isna().sum().sort_values()\ntrain_eda = train_eda.dropna(axis = 0) #removing all rows with NA\n\nX = train_eda[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n\nX = pd.concat([X,pd.get_dummies(data = train_eda[[\"Sex\", \"Embarked\", \"Pclass\"]], columns = [\"Sex\", \"Embarked\", \"Pclass\"])], axis = 1)\n\nX.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nFirst 5 rows of `y`\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ny = train_eda[\"Survived\"].values\ny[0:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\narray([0, 1, 1, 1, 0], dtype=int64)\n```\n:::\n:::\n\n\nChecking dimensions of `y` & `X`\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nlen(y) #889 after filling up the NA. previously 712\nX.shape #(889, 12)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n(889, 12)\n```\n:::\n:::\n\n\n### Normalising the data\n\nTransform `X` and printing the first 5 datapoints\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn import preprocessing\n\nX= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([[-0.56367407,  0.43135024, -0.47432585, -0.50023975, -0.73534203,\n         0.73534203, -0.48271079, -0.30794088,  0.61679395, -0.56306042,\n        -0.51087465,  0.90032807],\n       [ 0.66921696,  0.43135024, -0.47432585,  0.78894661,  1.35991138,\n        -1.35991138,  2.07163382, -0.30794088, -1.62128697,  1.77600834,\n        -0.51087465, -1.11070624],\n       [-0.25545131, -0.47519908, -0.47432585, -0.48664993,  1.35991138,\n        -1.35991138, -0.48271079, -0.30794088,  0.61679395, -0.56306042,\n        -0.51087465,  0.90032807],\n       [ 0.43804989,  0.43135024, -0.47432585,  0.42286111,  1.35991138,\n        -1.35991138, -0.48271079, -0.30794088,  0.61679395,  1.77600834,\n        -0.51087465, -1.11070624],\n       [ 0.43804989, -0.47519908, -0.47432585, -0.4841333 , -0.73534203,\n         0.73534203, -0.48271079, -0.30794088,  0.61679395, -0.56306042,\n        -0.51087465,  0.90032807]])\n```\n:::\n:::\n\n\n### Splitting into Test & Train data\n\nSplitting into `test` & `train` data and comparing the dimensions.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set\\t :', X_train.shape,  y_train.shape,\n'\\nTest set\\t :', X_test.shape,  y_test.shape)\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain set\t : (711, 12) (711,) \nTest set\t : (178, 12) (178,)\n```\n:::\n:::\n\n\n### K Nearest Neighbours\n\nUsing KNN at k = 4\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 4\nneighbours = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneighbours\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nKNeighborsClassifier(n_neighbors=4)\n```\n:::\n:::\n\n\n#### Predicting the output `yhat` and checking accuracy\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nyhat1 = neighbours.predict(X_test)\nyhat1[0:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\narray([0, 1, 0, 0, 1], dtype=int64)\n```\n:::\n:::\n\n\nCalculating the accuracy at k = 4\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn import metrics\n\nprint(\"Train set Accuracy \\t:\", metrics.accuracy_score(y_train, neighbours.predict(X_train)), \"\\nTest set Accuracy \\t:\", metrics.accuracy_score(y_test, yhat1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain set Accuracy \t: 0.8509142053445851 \nTest set Accuracy \t: 0.7584269662921348\n```\n:::\n:::\n\n\n*(without replacing `na` values, the previous test accuracy was 78%)*\n\n#### Checking for other K\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfrom sklearn import metrics\n\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\n\nfor n in range(1,Ks):\n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\narray([0.78651685, 0.76404494, 0.7752809 , 0.75842697, 0.78089888,\n       0.78651685, 0.80337079, 0.7752809 , 0.78089888])\n```\n:::\n:::\n\n\nGlad that IBM coursera assignments came in handy! Now visualising the accuracy across each `K`\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.fill_between(range(1,Ks),mean_acc - 3 * std_acc,mean_acc + 3 * std_acc, alpha=0.10,color=\"green\")\nplt.legend(('Accuracy ', '+/- 1xstd','+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Neighbors (K)')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index.en_files/figure-html/cell-16-output-1.png){width=661 height=468}\n:::\n:::\n\n\nLooks like accuracy of KNN is best at 7 neighbours. *previously without replacing NA the accuracy was highest at k = 5*\n\n#### Redo with `K = 7`\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nk = 7\n\nneighbours_7 = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nyhat = neighbours_7.predict(X_test)\n\nprint(\"Train set Accuracy \\t:\", metrics.accuracy_score(y_train, neighbours_7.predict(X_train)),\"\\nTest set Accuracy \\t:\", metrics.accuracy_score(y_test, yhat),\"\\nRMSE \\t\\t\\t:\",metrics.mean_squared_error(y_test, yhat),\"\\nNormalised RMSE\\t\\t:\",metrics.mean_squared_error(y_test, yhat)/np.std(y_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain set Accuracy \t: 0.8509142053445851 \nTest set Accuracy \t: 0.8033707865168539 \nRMSE \t\t\t: 0.19662921348314608 \nNormalised RMSE\t\t: 0.3997716243033934\n```\n:::\n:::\n\n\nWe find that Test accuracy is around **80% for KNN**[^1] with **RMSE of 0.197** and **Normalised RMSE of 40%**[^2]. [formula for NRMSE here](https://www.marinedatascience.co/blog/2019/01/07/normalizing-the-rmse/)\n\n[^1]: *pretty much the same as previous attempt before replacing NA*\n\n[^2]: *actually NRMSE is not needed as all models are of the same scale. This is used typically for model comparisons across log, decimal etc scales*\n\n",
    "supporting": [
      "index.en_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}