{
  "hash": "0fded7b4c38357a84f94f28b1dd1f4a8",
  "result": {
    "markdown": "---\ntitle: \"Day 8 of #50daysofkaggle\"\nauthor: ''\ndate: '2022-10-14'\nslug: day-8-of-kaggle\ncategories: [kaggle]\nsubtitle: 'Decision Tree'\nsummary: 'Classification through Decision Trees'\nauthors: []\nlastmod: '2022-10-14T09:32:49+05:30'\nfeatured: no\nimage: titanic_DT.jpg\nprojects: [50daysofkaggle]\nexecute: \n  warning: true\nformat:\n  html:\n    code-fold: true\n    code-block-border-left: true\n    toc: true\n---\n\n# Day 8: Titanic Dataset\n\nProgress till date:\n\n-   Download titanic dataset and assign to `train` & `test`\n-   Rearranging the data\n-   EDA (including plots and finding survival rate using `.groupby()`)\n-   Modelling\n-   Data preparation - one-hot encoding the `Sex`, `Pclass` & `Embarked` columns - appending these to the numerical columns - normalising the data - splitting between `train` into `X_train`, `y_train`, `X_test`, `y_test`\n-   Applying KNN algo\n    -   finding the right K based on accuracy. (best at K = 7)\n    -   Calculating the accuracy based on `test`\n\nTo do today: - Perform Decision Tree classification\n\n## Loading the data\n\nReading and printing the top 5 rows\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport zipfile\n\n\n#importing the zipfile already saved in the other folder. \nzf = zipfile.ZipFile(\"../2022-10-12-day-6-of-50daysofkaggle/titanic.zip\")\ntrain = pd.read_csv(zf.open(\"train.csv\"))\ntest = pd.read_csv(zf.open(\"test.csv\"))\n\n#Selecting only the numerical columns\nnum_col = train.select_dtypes(include=np.number).columns.tolist()\n\n#deslecting passenger ID and 'Survived' \ndel num_col[0:2] #.remove() can remove only 1 item. so for more than 1, use for loop \nselect_col = num_col\n\n#remaining columns\nstr_col= [\"Sex\", \"Embarked\", \"Survived\"]\n\n\n#Adding more elements into a list using `extend` and not `append`\nselect_col.extend(str_col)\n\ntrain_eda= train[train.columns.intersection(select_col)]\ntrain_eda.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Cleaning up the data\n\nChecking all `na` values in the existing dataset\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ntrain_eda.isna().sum().sort_values()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\nSurvived      0\nPclass        0\nSex           0\nSibSp         0\nParch         0\nFare          0\nEmbarked      2\nAge         177\ndtype: int64\n```\n:::\n:::\n\n\nFinding the mean\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ntrain_eda[\"Age\"].median()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n28.0\n```\n:::\n:::\n\n\nReplacing `na` cells with the mean\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ntrain_eda[\"Age\"].fillna(value = train_eda[\"Age\"].median(), inplace = True)\ntrain_eda.isna().sum().sort_values()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9908\\1076914416.py:1: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nSurvived    0\nPclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nEmbarked    2\ndtype: int64\n```\n:::\n:::\n\n\n**Sidenote**: Was getting a wierd warning (`SettingWithCopyWarning`) while using `.fillna()` to replace na with the median values. Turns out there's a between calling a view or a copy. One way of avoiding this error is to use `train_eda.loc[:,\"Age\"]` instead of `train_eda[\"Age\"]`. This is because `.loc` returns the view (original) while using subsets. [Elegant explanation here](https://stackoverflow.com/a/54914752/7938068 \"Stockoverflow solution\"). Below code will not throw up a warning.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nxx = train_eda.copy()\nxx.loc[:,\"Age\"].fillna(value = xx.Age.median(), inplace = True)\nxx.isna().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nSurvived    0\nPclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nEmbarked    2\ndtype: int64\n```\n:::\n:::\n\n\n## Model Building\n\nSeperating X & y. Here's the first 5 rows of X\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ntrain_eda = train_eda.dropna(axis = 0) #removing all rows with NA\n\nX = train_eda[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\nX = pd.concat([X,pd.get_dummies(data = train_eda[[\"Sex\", \"Embarked\", \"Pclass\"]], columns = [\"Sex\", \"Embarked\", \"Pclass\"])], axis = 1)\n\nX.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nHere's the first 5 rows of `y`\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ny = train_eda[\"Survived\"].values\ny[0:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\narray([0, 1, 1, 1, 0], dtype=int64)\n```\n:::\n:::\n\n\ncomparing the shapes of `X` and `y`\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nlen(y) #889 after filling up the NA. previously 712\nX.shape #(889, 12)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n(889, 12)\n```\n:::\n:::\n\n\n### Normalising the data\n\nStandardising and printing the first 5 datapoints.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn import preprocessing\n\nX= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([[-0.56367407,  0.43135024, -0.47432585, -0.50023975, -0.73534203,\n         0.73534203, -0.48271079, -0.30794088,  0.61679395, -0.56306042,\n        -0.51087465,  0.90032807],\n       [ 0.66921696,  0.43135024, -0.47432585,  0.78894661,  1.35991138,\n        -1.35991138,  2.07163382, -0.30794088, -1.62128697,  1.77600834,\n        -0.51087465, -1.11070624],\n       [-0.25545131, -0.47519908, -0.47432585, -0.48664993,  1.35991138,\n        -1.35991138, -0.48271079, -0.30794088,  0.61679395, -0.56306042,\n        -0.51087465,  0.90032807],\n       [ 0.43804989,  0.43135024, -0.47432585,  0.42286111,  1.35991138,\n        -1.35991138, -0.48271079, -0.30794088,  0.61679395,  1.77600834,\n        -0.51087465, -1.11070624],\n       [ 0.43804989, -0.47519908, -0.47432585, -0.4841333 , -0.73534203,\n         0.73534203, -0.48271079, -0.30794088,  0.61679395, -0.56306042,\n        -0.51087465,  0.90032807]])\n```\n:::\n:::\n\n\n### Splitting into Test & Train data\n\nSplitting into `test` & `train` data and comparing the dimensions.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set\\t :', X_train.shape,  y_train.shape,\n'\\nTest set\\t :', X_test.shape,  y_test.shape)\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain set\t : (711, 12) (711,) \nTest set\t : (178, 12) (178,)\n```\n:::\n:::\n\n\n### Decision Trees\n\nLets check the classification results using Decision trees. First 10 are as follows:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom sklearn.tree import DecisionTreeClassifier\n\nDtree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 3)\nDtree.fit(X_train,y_train)\ny_test_hat = Dtree.predict(X_test)\nprint(\"First 10 actual\\t\\t:\", y_test[0:10],\"\\nFirst 10 predicted\\t:\", y_test_hat[0:10])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFirst 10 actual\t\t: [1 1 0 1 1 1 0 0 0 0] \nFirst 10 predicted\t: [1 1 0 1 1 0 0 0 0 0]\n```\n:::\n:::\n\n\n### Checking Accuracy of DT\n\nCalculating accuracy using Decision Tree classification for `y_test`\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn import metrics\n\nprint(\"Decision Tree Accuracy\\t:\", metrics.accuracy_score(y_test, y_test_hat),\"\\nRMSE\\t\\t\\t:\", metrics.mean_squared_error(y_test,y_test_hat),\"\\nNormalised RMSE\\t\\t:\", metrics.mean_squared_error(y_test,y_test_hat)/np.std(y_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDecision Tree Accuracy\t: 0.8314606741573034 \nRMSE\t\t\t: 0.16853932584269662 \nNormalised RMSE\t\t: 0.34266139226005143\n```\n:::\n:::\n\n\nNot bad. We find that Test accuracy is around **83% for Decision Trees** and **RMSE of 0.168**\n\n### Visualising the DT\n\nHere's a neat little trick to see how the DT actually thinks.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn import tree\nimport matplotlib.pyplot as plt\n\nplt.clf()\ntree.plot_tree(Dtree)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index.en_files/figure-html/cell-14-output-1.png){width=540 height=382}\n:::\n:::\n\n\n",
    "supporting": [
      "index.en_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}