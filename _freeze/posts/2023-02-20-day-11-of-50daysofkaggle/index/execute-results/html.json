{
  "hash": "aaa8447cf50996d34ccf131e26f3e598",
  "result": {
    "markdown": "---\ntitle: \"Day 11 of #50daysofkaggle\"\nsubtitle: \"Roadmap to tidymodels\"\ndescription: \"Implementing DT using R\"\ndate: '2023-02-20'\ncategories: [kaggle, R]\nfeatured: no\nimage: titanic_tidymodels.jpg\nexecute:\n  warning: false\n---\n\n\nTill now I practiced creating classification predictions on the Titanic dataset using KNN, DT and SVM algorithms. As per Kaggle, [my submission got a score of 77%](https://www.kaggle.com/code/dsramakant/titanic-classification-by-decision-trees-python). Now I'm going to try these approaches in R.\n\nsteps to do : data reading \\> cleaning \\> replacing NA \\> splitting \\> model using Decision Trees\\> comparing results\n\n# Data reading and cleaning\n\nloading the necessary libraries & reading `train.csv` from a zipped file. Taking a glimpse of the resulting `df`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(zip)\nlibrary(readr)\nlibrary(tidymodels)\n\n#reading kaggle zip file that I downloaded in older folder\nziplocation <- \"D:/Ramakant/Personal/Weekends in Mumbai/Blog/quarto_blog/posts/2022-10-12-day-6-of-50daysofkaggle/titanic.zip\"\ndf <-  read_csv(unz(ziplocation, \"train.csv\"))\nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 891\nColumns: 12\n$ PassengerId <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    <dbl> 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      <dbl> 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        <chr> \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         <chr> \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         <dbl> 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       <dbl> 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      <chr> \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        <dbl> 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       <chr> NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    <chr> \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n```\n:::\n:::\n\n\nReformatting the `df` to create a new tibble `df_n`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_n <- df %>% \n  #selecting only the numerical variables\n  select_if(is.numeric) %>% \n  #converting outcome variable into factor for classification \n  mutate(Survived = as.factor(Survived)) %>% \n  #adding back the Sex & Embarked predictors\n  bind_cols(Sex = df$Sex, Embarked = df$Embarked) \n\nhead(df_n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  PassengerId Survived Pclass   Age SibSp Parch  Fare Sex    Embarked\n        <dbl> <fct>     <dbl> <dbl> <dbl> <dbl> <dbl> <chr>  <chr>   \n1           1 0             3    22     1     0  7.25 male   S       \n2           2 1             1    38     1     0 71.3  female C       \n3           3 1             3    26     0     0  7.92 female S       \n4           4 1             1    35     1     0 53.1  female S       \n5           5 0             3    35     0     0  8.05 male   S       \n6           6 0             3    NA     0     0  8.46 male   Q       \n```\n:::\n:::\n\n\nFinding the null values in the new df\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_n %>%  \n  summarise_all(~ sum(is.na(.)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 9\n  PassengerId Survived Pclass   Age SibSp Parch  Fare   Sex Embarked\n        <int>    <int>  <int> <int> <int> <int> <int> <int>    <int>\n1           0        0      0   177     0     0     0     0        2\n```\n:::\n:::\n\n\nWe see that there are 177 null values in the `Age` column. This will be tackled in the recipe section along with `PassengerId`\n\n# Model Building\n\n## Splitting the data \n\nSplitting the data into train & test\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_split <- initial_split(df_n, prop = 0.8)\ntrain <- training(df_split)\ntest <- testing(df_split)\n\ndf_split\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Training/Testing/Total>\n<712/179/891>\n```\n:::\n:::\n\n\ncreating the recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt_recipe <- recipe(Survived ~ ., data = df_n) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  #replacing NA values in Age with median Age\n  step_mutate_at(Age, fn = ~ replace_na(Age, median(Age, na.rm = T))) %>% \n  #updating the role of the PassengerId to exclude from analysis\n  update_role(PassengerId, new_role = \"id_variable\")\n\ndt_recipe\n```\n:::\n\n\nAnother way to view the recipe using `tidy()` function\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(dt_recipe)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 6\n  number operation type      trained skip  id             \n   <int> <chr>     <chr>     <lgl>   <lgl> <chr>          \n1      1 step      dummy     FALSE   FALSE dummy_jD1sy    \n2      2 step      normalize FALSE   FALSE normalize_CvfCk\n3      3 step      mutate_at FALSE   FALSE mutate_at_xAmJj\n```\n:::\n:::\n\n\n## Model Creation\n\nDeclaring a model `dt_model` as a Decision Tree with depth as 3 and engine `rpart`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt_model <- decision_tree(mode = \"classification\", tree_depth = 3) %>% \n  set_engine(\"rpart\")\ndt_model %>% translate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  tree_depth = 3\n\nComputational engine: rpart \n\nModel fit template:\nrpart::rpart(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n    maxdepth = 3)\n```\n:::\n:::\n\n\n## Workflow creation\n\n**Workflow = recipe + model**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt_wf <- workflow() %>%\n  add_model(dt_model) %>% \n  add_recipe(dt_recipe)\n```\n:::\n\n\n## Predicting on `test` data \n\nFitting the `dt_wf` workflow with model created on `train` data to predict the `test` data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2023)\ndt_predict <- predict(fit(dt_wf, data = train), test)\nhead(dt_predict)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 1\n  .pred_class\n  <fct>      \n1 0          \n2 0          \n3 0          \n4 1          \n5 0          \n6 0          \n```\n:::\n:::\n\n\nCreating a new tibble called `preidcted_table` by binding the predicted values `.pred_class` to the `test` data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredicted_table <- bind_cols(test, dt_predict) %>% \n  rename(dt_yhat = .pred_class) %>% \n  select(Survived, dt_yhat) \nhead(predicted_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n  Survived dt_yhat\n  <fct>    <fct>  \n1 0        0      \n2 0        0      \n3 0        0      \n4 0        1      \n5 0        0      \n6 0        0      \n```\n:::\n:::\n\n\n# Testing accuracy\n\nAs mentioned in the [TMRW documentation for binary classification metrics](https://www.tmwr.org/performance.html#binary-classification-metrics), we will try creating the confusion matrix and checking accuracy\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(predicted_table, truth = Survived, estimate = dt_yhat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction   0   1\n         0 109  22\n         1  11  37\n```\n:::\n:::\n\n\nEstimating the accuracy of our model\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(predicted_table, truth = Survived, estimate = dt_yhat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.816\n```\n:::\n:::\n\n\nIn the `tidymodels` approach, we can define the required metrics with `metric_set` seperately to check the model accuracy\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclassification_metrics <- metric_set(accuracy, f_meas)\npredicted_table %>% \n  classification_metrics(truth = Survived, estimate = dt_yhat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.816\n2 f_meas   binary         0.869\n```\n:::\n:::\n\n\n# Submission on Kaggle\n\nWhen I ran this code on Kaggle, the [Decision Tree predictions resulted in a score of 0.7799](https://www.kaggle.com/code/dsramakant/decision-tree-with-tidymodels-v01/notebook). Exactly similar to the [DT code written in python earlier](https://www.kaggle.com/code/dsramakant/titanic-classification-by-decision-trees-python/notebook).\n\nOverall, I'm glad that I was able to wrap my head around the `tidymodels` workflow.\n\n# Next steps\n\n-   Figure out how to compare accuracy of different models (KNN, SVM) that I had coded earlier in python\n-   figure out hyper-parameter tuning from the `tune()` package\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}