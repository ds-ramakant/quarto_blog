{
  "hash": "f7821e244b3026ee08124cdb030d334a",
  "result": {
    "markdown": "---\ntitle: \"Day 11 of #50daysofkaggle\"\nsubtitle: \"Roadmap to tidymodels\"\ndescription: \"Titanic dataset in R\"\ndate: '2023-02-20'\ncategories: [kaggle, R]\nfeatured: no\nimage: titanic.jpg\n---\n\n\nTill now I practiced creating classification predictions on the Titanic dataset using KNN, DT and SVM algorithms. As per Kaggle, [my submission got a score of 77%](https://www.kaggle.com/code/dsramakant/titanic-classification-by-decision-trees-python). Now I'm going to try these approaches in R.\n\nsteps to do : data reading \\> cleaning \\> replacing NA \\> splitting \\> model using Decision Trees\\> comparing results\n\n# Data reading and cleaning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.5\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(zip)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'zip'\n\nThe following objects are masked from 'package:utils':\n\n    unzip, zip\n```\n:::\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.1     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.3\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.4     ✔ yardstick    1.1.0\n✔ recipes      1.0.5     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n```\n:::\n\n```{.r .cell-code}\n#reading kaggle zip file that I downloaded in older folder\nziplocation <- \"D:/Ramakant/Personal/Weekends in Mumbai/Blog/quarto_blog/posts/2022-10-12-day-6-of-50daysofkaggle/titanic.zip\"\ndf <-  read_csv(unz(ziplocation, \"train.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 891 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Name, Sex, Ticket, Cabin, Embarked\ndbl (7): PassengerId, Survived, Pclass, Age, SibSp, Parch, Fare\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ndf %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 12\n  PassengerId Survived Pclass Name    Sex     Age SibSp Parch Ticket  Fare Cabin\n        <dbl>    <dbl>  <dbl> <chr>   <chr> <dbl> <dbl> <dbl> <chr>  <dbl> <chr>\n1           1        0      3 Braund… male     22     1     0 A/5 2…  7.25 <NA> \n2           2        1      1 Cuming… fema…    38     1     0 PC 17… 71.3  C85  \n3           3        1      3 Heikki… fema…    26     0     0 STON/…  7.92 <NA> \n4           4        1      1 Futrel… fema…    35     1     0 113803 53.1  C123 \n5           5        0      3 Allen,… male     35     0     0 373450  8.05 <NA> \n6           6        0      3 Moran,… male     NA     0     0 330877  8.46 <NA> \n# … with 1 more variable: Embarked <chr>\n```\n:::\n\n```{.r .cell-code}\n#selecting numerical features and removing PassengerID & Survived\n\nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 891\nColumns: 12\n$ PassengerId <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    <dbl> 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      <dbl> 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        <chr> \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         <chr> \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         <dbl> 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       <dbl> 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      <chr> \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        <dbl> 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       <chr> NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    <chr> \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n```\n:::\n\n```{.r .cell-code}\ndf_n <- df %>% \n  select_if(is.numeric) %>% \n  select(-PassengerId)\n\ndf_n <- df_n %>% \n  bind_cols(Sex = df$Sex, Embarked = df$Embarked) \nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 891\nColumns: 12\n$ PassengerId <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    <dbl> 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      <dbl> 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        <chr> \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         <chr> \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         <dbl> 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       <dbl> 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      <chr> \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        <dbl> 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       <chr> NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    <chr> \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n```\n:::\n\n```{.r .cell-code}\n#finding null values\n\ndf_n$Survived <- as.factor(df_n$Survived)\n\ndf_n %>%  \n  summarise_all(~ sum(is.na(.)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  Survived Pclass   Age SibSp Parch  Fare   Sex Embarked\n     <int>  <int> <int> <int> <int> <int> <int>    <int>\n1        0      0   177     0     0     0     0        2\n```\n:::\n:::\n\n\nFinding the mean of `Age` values and replacing NA values in `Age`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian(df_n$Age, na.rm = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 28\n```\n:::\n\n```{.r .cell-code}\ndf_n <- df_n %>% \n  mutate(Age = replace_na(Age, median(Age, na.rm = T)))\n\ndf_n %>% summarise_all(~sum(is.na(.)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  Survived Pclass   Age SibSp Parch  Fare   Sex Embarked\n     <int>  <int> <int> <int> <int> <int> <int>    <int>\n1        0      0     0     0     0     0     0        2\n```\n:::\n:::\n\n\n# Model Building\n\nSplitting the data into train & test\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_split <- initial_split(df_n, prop = 0.8)\ntrain <- training(df_split)\ntest <- testing(df_split)\n\ndf_split\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Training/Testing/Total>\n<712/179/891>\n```\n:::\n:::\n\n\ncreating the recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_engines(\"decision_tree\") #shows the list of engines & modes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 2\n  engine mode          \n  <chr>  <chr>         \n1 rpart  classification\n2 rpart  regression    \n3 C5.0   classification\n4 spark  classification\n5 spark  regression    \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndt_recipe <- recipe(Survived ~ ., data = df_n) %>% \n  #reomving NA rows in Embarked columns\n  step_naomit(Embarked) %>% \n  #replacing NA values in Age with median Age\n  step_mutate_at(Age, fn = ~ replace_na(Age, median(Age, na.rm = T))) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_normalize(all_numeric_predictors()) \n  \n  \n  \n  # %>% step_mutate_at(Survived, fn = ~as_factor(Survived))\n\ndt_recipe\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Inputs \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nNumber of variables by role\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\noutcome:   1\npredictor: 7\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Operations \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Removing rows with NA values in: Embarked\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Variable mutation for: Age\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Dummy variables from: all_nominal_predictors()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Centering and scaling for: all_numeric_predictors()\n```\n:::\n\n```{.r .cell-code}\ntidy(dt_recipe)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 6\n  number operation type      trained skip  id             \n   <int> <chr>     <chr>     <lgl>   <lgl> <chr>          \n1      1 step      naomit    FALSE   TRUE  naomit_v5LGU   \n2      2 step      mutate_at FALSE   FALSE mutate_at_4Ocnv\n3      3 step      dummy     FALSE   FALSE dummy_Sfkr8    \n4      4 step      normalize FALSE   FALSE normalize_5Lshi\n```\n:::\n\n```{.r .cell-code}\ndt_model <- decision_tree(mode = \"classification\", tree_depth = 3) %>% \n  set_engine(\"rpart\")\n\ndt_model %>% translate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  tree_depth = 3\n\nComputational engine: rpart \n\nModel fit template:\nrpart::rpart(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n    maxdepth = 3)\n```\n:::\n:::\n\n\nCreating a workflow based on the model \\> fitting data \\> predicting the results\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt_wf <- workflow() %>%\n  add_model(dt_model) %>% \n  add_recipe(dt_recipe)\n\n\ndt_predict <- predict(fit(dt_wf, data = train), test)\n\ntest_n <- bind_cols(test, dt_predict)\ntest_n <- test_n %>% \n  rename(dt_yhat = .pred_class)\n\npredicted_table <- test_n %>% \n  select(Survived, dt_yhat) \n\n#this table converts factors to numeric values\npredicted_table2 <- test_n %>% \n  select(Survived, dt_yhat) %>% \n#convert factor to numeric\n mutate(across(where(is.factor), as.numeric)) %>%\n#conversion takes values 1 & 2 instead of 0 & 1, hence correcting back\n mutate(across(1:2, ~.x -1))\n\npredicted_table2 %>% rmse(dt_yhat, Survived)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       0.442\n```\n:::\n:::\n\n\n# Testing accuracy\n\nAs mentioned in the [TMRW documentation for binary classification metrics](https://www.tmwr.org/performance.html#binary-classification-metrics), we will try creating the confusion matrix and checking accuracy\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredicted_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 179 × 2\n   Survived dt_yhat\n   <fct>    <fct>  \n 1 1        1      \n 2 1        1      \n 3 1        0      \n 4 1        0      \n 5 0        1      \n 6 0        0      \n 7 0        1      \n 8 0        0      \n 9 1        1      \n10 1        1      \n# … with 169 more rows\n```\n:::\n\n```{.r .cell-code}\nconf_mat(predicted_table, truth = Survived, estimate = dt_yhat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction  0  1\n         0 95 22\n         1 13 49\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(predicted_table, truth = Survived, estimate = dt_yhat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.804\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nclassification_metrics <- metric_set(accuracy, f_meas)\n\npredicted_table %>% \n  classification_metrics(truth = Survived, estimate = dt_yhat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.804\n2 f_meas   binary         0.844\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}