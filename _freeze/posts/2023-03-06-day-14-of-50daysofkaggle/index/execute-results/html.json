{
  "hash": "b310e5eb3f9679f363a29c689b2d37b9",
  "result": {
    "markdown": "---\ntitle: \"Day 14 of #50daysofKaggle\"\nsubtitle: \"Roadmap to Tidymodels - Part 2\"\ndescription: \"Screening multiple models using workflows\"\ndate: '2023-03-20'\ncategories: [R, kaggle]\nfeatured: no\nexecute:\n  warning: false\nimage: Rplot.png\n---\n\n\nHow hard is it to evaluate multiple models when working on a given data problem?\n\nIf you're using the `tidymodels` package, the answer is surprisingly simple.\n\nToday's post is an attempt to use the `tidymodels` framework to screen multiple models. Inspiration for this post comes from the [Ch 15 of the Tidymodels with R textbook](https://www.tmwr.org/workflow-sets.html) along with two more noteworthy blogs\n\n-   [Olivier Gimenez's post](https://oliviergimenez.github.io/blog/learning-machine-learning/) that had me marvelling at the feature engineering\n-   [Tural Sadigov's post](https://rpubs.com/tsadigov/titanic_tidymodels) on handling multiple models\n\nI'm skipping the EDA component as I've covered it in the previous posts. Moving on to some boring (but very necessary) sections.\n\nAs always, please feel free to leave a comment using the side-barüëâüèº\n\n# Loading the data\n\n`test` and `train` data is inputted and merged into a single dataframe\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\ntitanic_train <- read.csv(\"train.csv\", header = T)\n\n#adding column to identify source\ntitanic_train <- titanic_train %>% \n  mutate(source = \"train\")\n\ntitanic_test <- read.csv(\"test.csv\", header = T)\n#adding column to identify source\ntitanic_test <- titanic_test %>% \n  mutate(Survived = NA,\n         source = \"test\")\n\n#merging the data. step1 starts here\ntitanic_data <- bind_rows(titanic_train, titanic_test)\n\nglimpse(titanic_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,309\nColumns: 13\n$ PassengerId <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,‚Ä¶\n$ Survived    <int> 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1‚Ä¶\n$ Pclass      <int> 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3‚Ä¶\n$ Name        <chr> \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl‚Ä¶\n$ Sex         <chr> \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal‚Ä¶\n$ Age         <dbl> 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, ‚Ä¶\n$ SibSp       <int> 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0‚Ä¶\n$ Parch       <int> 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0‚Ä¶\n$ Ticket      <chr> \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37‚Ä¶\n$ Fare        <dbl> 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,‚Ä¶\n$ Cabin       <chr> \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C‚Ä¶\n$ Embarked    <chr> \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"‚Ä¶\n$ source      <chr> \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"tra‚Ä¶\n```\n:::\n:::\n\n\n## Cleaning data\n\nChecking for `NA` values in the full df tells us that Age column has 86 missing in `test` & 177 missing values in `train` while there's 1 missing NA value in Fare. The 418 missing values in Survived in `test` are the ones we need to predict.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  group_by(source) %>% \n  summarise_all(~ sum(is.na(.)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 √ó 13\n  source Passe‚Ä¶¬π Survi‚Ä¶¬≤ Pclass  Name   Sex   Age SibSp Parch Ticket  Fare Cabin\n  <chr>    <int>   <int>  <int> <int> <int> <int> <int> <int>  <int> <int> <int>\n1 test         0     418      0     0     0    86     0     0      0     1     0\n2 train        0       0      0     0     0   177     0     0      0     0     0\n# ‚Ä¶ with 1 more variable: Embarked <int>, and abbreviated variable names\n#   ¬π‚ÄãPassengerId, ¬≤‚ÄãSurvived\n```\n:::\n:::\n\n\n### Janitor::clean_names()\n\nNow i've got a thing about keeping column names clean so summoning `janitor` with a magic wand:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data <- titanic_data %>% \n  mutate(family_count = SibSp+Parch+1) %>% \n  janitor::clean_names()\nnames(titanic_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"passenger_id\" \"survived\"     \"pclass\"       \"name\"         \"sex\"         \n [6] \"age\"          \"sib_sp\"       \"parch\"        \"ticket\"       \"fare\"        \n[11] \"cabin\"        \"embarked\"     \"source\"       \"family_count\"\n```\n:::\n:::\n\n\nVoila. Everything now in lower case and snake case!\n\n### Imputing `NA` values in `embarked`\n\nNow under **embarked** there are two rows that don't have `NA` but are blank. That's a bit oddü§®\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  count(embarked, sort = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  embarked   n\n1        S 914\n2        C 270\n3        Q 123\n4            2\n```\n:::\n:::\n\n\nSince it is only 2 such rows, I'll be replacing the `NA` values with the most repeated **embarked** value. So now zero empty values in **embarked**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmode_embarked <- titanic_data %>% \n  count(embarked, sort = T) %>% \n  select(embarked) %>% \n  head(1) %>% \n#this beautiful func comes from the purrr package. equivalent of .[[1]]\n  pluck(1)\n\ntitanic_data <- titanic_data %>% \n  mutate(embarked = if_else(embarked == \"\", mode_embarked, embarked))\n\ntitanic_data %>% \n  count(embarked, sort = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  embarked   n\n1        S 916\n2        C 270\n3        Q 123\n```\n:::\n:::\n\n\n### Imputing `NA` values in `age`\n\nThe **age** column has a bunch of missing values. My approach today is to substitute them with the median values when grouped by **sex** and **class**. Here's a function written to impute within the test and train data accordingly.\n\n*note: Feature engineering functions can be addressed in the `tidymodels`* *framework at recipe stage.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian_age_calc <- function(df){\n  median_ages <- df %>% \n    group_by(sex, pclass) %>% \n    summarise(age = median(age,na.rm = T))\n  df %>%\n    mutate(age = case_when((sex ==\"male\" & pclass ==1 & is.na(age)) ~ median_ages$age[1],\n                           (sex ==\"male\" & pclass ==2 & is.na(age)) ~ median_ages$age[2],\n                           (sex ==\"male\" & pclass ==3 & is.na(age)) ~ median_ages$age[3],\n                           (sex ==\"female\" & pclass ==1 & is.na(age)) ~ median_ages$age[4],\n                           (sex ==\"female\" & pclass ==2 & is.na(age)) ~ median_ages$age[5],\n                           (sex ==\"female\" & pclass ==3 & is.na(age)) ~ median_ages$age[6],\n                           .default = age)\n    )\n}\n\ntitanic_data <- titanic_data %>% \n  median_age_calc() %>% ungroup()\n```\n:::\n\n\nAre there any `na` values in the titanic data now?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  select(source, survived, sex, pclass, fare, age) %>% \n  group_by(source) %>% \n  summarise_all(~ sum(is.na(.)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 √ó 6\n  source survived   sex pclass  fare   age\n  <chr>     <int> <int>  <int> <int> <int>\n1 test        418     0      0     1     0\n2 train         0     0      0     0     0\n```\n:::\n:::\n\n\nPhew. So age is covered. What are the median values now?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  group_by(pclass, sex) %>%\n  summarise(median_age = median(age))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 √ó 3\n# Groups:   pclass [3]\n  pclass sex    median_age\n   <int> <chr>       <dbl>\n1      1 female       37.5\n2      1 male         37  \n3      2 female       28  \n4      2 male         28  \n5      3 female       25  \n6      3 male         22  \n```\n:::\n:::\n\n\n### Imputing `NA` values for `fare`\n\nThere's this one person (passenger_id = 1044, male and pclass = 3) who has a `na` value in **fare** from `test` data. Replacing it with the median value.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  select(source, name, passenger_id, sex, age, pclass, fare) %>% \n  filter(is.na(fare))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  source               name passenger_id  sex  age pclass fare\n1   test Storey, Mr. Thomas         1044 male 60.5      3   NA\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  group_by(sex, pclass) %>% \n  summarise(median_fare = median(fare, na.rm = T))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 √ó 3\n# Groups:   sex [2]\n  sex    pclass median_fare\n  <chr>   <int>       <dbl>\n1 female      1       80.9 \n2 female      2       23   \n3 female      3       10.5 \n4 male        1       49.5 \n5 male        2       13   \n6 male        3        7.90\n```\n:::\n:::\n\n\nReplacing in the main df\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data <- titanic_data %>% \n  mutate(fare = if_else(is.na(fare), \n#from the above table. Urgh!! hard coding for that 1 guy!! how inelegant.\n                        7.8958, age))\n```\n:::\n\n\nchecking if has been replaced.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  select(source, name, passenger_id, sex, age, pclass, fare) %>% \n  filter(is.na(fare))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] source       name         passenger_id sex          age         \n[6] pclass       fare        \n<0 rows> (or 0-length row.names)\n```\n:::\n:::\n\n\n# Feature Engineering\n\nFor this post, I've focussed on a different approach while predicting survival probabilities. The guiding principle here is to club passengers from the same family and/or the same ticket_ID. The `titanic` dataset poses the challenge of having people within the same family purchase different tickets while at the same time so **surnames** really are not always the best grouping feature.\n\nOne such example is the Cacic family:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  select(name, sex,age, ticket, survived) %>% \n  filter(str_detect(name, \"Cacic\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  name    sex age ticket survived\n1      Cacic, Mr. Luka   male  38 315089        0\n2  Cacic, Miss. Marija female  30 315084        0\n3   Cacic, Miss. Manda female  21 315087       NA\n4 Cacic, Mr. Jego Grga   male  18 315091       NA\n```\n:::\n:::\n\n\nHow about only clubbing with only **surname**? Well, that also gets tricky because sometimes we have instances of people within the same **ticket** sharing multiple **surnames.**\n\nCase in point is ticket 1601:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  select(name, sex, age, ticket, survived) %>% \n  filter(ticket==1601)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             name  sex age ticket survived\n1   Bing, Mr. Lee male  32   1601        1\n2   Ling, Mr. Lee male  28   1601        0\n3  Lang, Mr. Fang male  26   1601        1\n4 Foo, Mr. Choong male  22   1601        1\n5    Lam, Mr. Ali male  22   1601        1\n6    Lam, Mr. Len male  22   1601        0\n7 Chip, Mr. Chang male  32   1601        1\n8   Hee, Mr. Ling male  22   1601       NA\n```\n:::\n:::\n\n\nIn times of crisis, it is expected that groups that traveled together will look out for their own. While this is not a thumb rule, I wanted to create a custom column that will combine the **ticket** and **surnames**.\n\nSo first step is to finding the surnames. That means using regex. Lovely ü§¢\n\n## Splitting names\n\nWith absolutely no guilt, I confess that this took me almost an entire day to figure out. And am I glad to have done it. The best thing about the tidyverse approach is the onus on making readable data. For that I'm grateful to discover functions like `seperate_wider_regex`.\n\nEssentially, it is a delimiter that breaks up columns based on the string patterns. So neat!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames_with_splchar <- regex(\"[A-Za-z]+[\\\\'\\\\-\\\\s]+[A-Za-z]+\")\nnames_with_3words <- regex(\"[A-Za-z]+\\\\s[A-Za-z]+\\\\s[A-Za-z]+\")\nnames_with_1word <- regex(\"[A-Za-z]+\") \nnames_with_2words <- regex(\"[A-Za-z]+\\\\s+[A-Za-z]+\") # for 'the countess'\n\n\ntitanic_data <- titanic_data %>% \n  separate_wider_regex(\n    name, \n    patterns = c(\n#IMP: ordering of regex patterns changes the outcome\n      surname = str_c(c(names_with_splchar, \n                        names_with_3words,\n                        names_with_1word), \n                      collapse = \"|\"),    # picks the first word before comma\n      \", \",                               # the comma  \n#IMP: ordering of regex patterns changes the outcome\n      title = str_c(c(names_with_2words , # two words with special char in between like 'the countess'\n                      names_with_1word),  # one word such as Mr Miss Mrs etc\n                    collapse = \"|\"),      \n      \". \",                               # the dot\n      given_name = \".+\"),                 # picks anything else which occurs at least once\n    cols_remove = F                       # retains the original column    \n  ) \n\ntitanic_data %>% \n  select(name, title, surname, given_name) %>% \n  head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 √ó 4\n   name                                                title  surname   given_‚Ä¶¬π\n   <chr>                                               <chr>  <chr>     <chr>   \n 1 Braund, Mr. Owen Harris                             Mr     Braund    Owen Ha‚Ä¶\n 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) Mrs    Cumings   John Br‚Ä¶\n 3 Heikkinen, Miss. Laina                              Miss   Heikkinen Laina   \n 4 Futrelle, Mrs. Jacques Heath (Lily May Peel)        Mrs    Futrelle  Jacques‚Ä¶\n 5 Allen, Mr. William Henry                            Mr     Allen     William‚Ä¶\n 6 Moran, Mr. James                                    Mr     Moran     James   \n 7 McCarthy, Mr. Timothy J                             Mr     McCarthy  Timothy‚Ä¶\n 8 Palsson, Master. Gosta Leonard                      Master Palsson   Gosta L‚Ä¶\n 9 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   Mrs    Johnson   Oscar W‚Ä¶\n10 Nasser, Mrs. Nicholas (Adele Achem)                 Mrs    Nasser    Nichola‚Ä¶\n# ‚Ä¶ with abbreviated variable name ¬π‚Äãgiven_name\n```\n:::\n:::\n\n\nWhat is the break-up of titles now?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data %>% \n  count(title, sort= T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 18 √ó 2\n   title            n\n   <chr>        <int>\n 1 Mr             757\n 2 Miss           260\n 3 Mrs            197\n 4 Master          61\n 5 Dr               8\n 6 Rev              8\n 7 Col              4\n 8 Major            2\n 9 Mlle             2\n10 Ms               2\n11 Capt             1\n12 Don              1\n13 Dona             1\n14 Jonkheer         1\n15 Lady             1\n16 Mme              1\n17 Sir              1\n18 the Countess     1\n```\n:::\n:::\n\n\n## Creating a custom grouping\n\nThe **ticket** is going to be broken up into **ticket_tail** (the last character) and **ticket_head** (all but the last character). Then we merge **surname** and **ticket_head** to create a **group_id**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data <- titanic_data %>% \n  mutate(ticket_head = substr(ticket, 1, nchar(ticket)-1),\n         ticket_tail = substr(ticket, nchar(ticket), nchar(ticket)),\n         group_id = paste0(surname, \"_\", ticket_head)) \n```\n:::\n\n\nCreating columns that indicate the number of people and other flags\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data <- titanic_data %>% \n  add_count(group_id) %>% rename(pax_in_group = n)\n\ntitanic_data <- titanic_data %>% \n  mutate(flag = case_when ((family_count==1 & pax_in_group==1) ~ \"1_solo\",\n                           family_count == pax_in_group ~ \"2_family_full\",\n                           !(family_count == pax_in_group) ~ \"3_clubbed\",\n                           .default = \"x\"))\n\ntitanic_data <- titanic_data %>% \n  add_count(ticket_head) %>% \n  rename(pax_in_ticket_head = n)\n\n# how many instances of the same ticket having multiple groups? \ntitanic_data <- titanic_data %>% \n  group_by(ticket) %>% \n  mutate(groups_in_ticket = n_distinct(group_id)) %>% ungroup()\n\n# which tickets that have more than 1 groups in them? \n#     these passengers will have ticket_grouping precedence as they may include \n#     nannies, relatives & friends that don't share the same surname\nticket_with_multiple_groups <- titanic_data %>% \n  filter(!groups_in_ticket==1) %>% \n  count(ticket, sort = T)\n\ntitanic_data <- titanic_data %>% \n  mutate(final_grouping = if_else(ticket %in% ticket_with_multiple_groups$ticket, \n                             ticket, group_id),\n         final_label = if_else(ticket %in% ticket_with_multiple_groups$ticket,\n                         \"4_ticket_grouping\", flag)) \n```\n:::\n\n\nSince the code now has become a bit too long and I'm creating a checkpost here with a new df called `titanic_data2`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_data2 <- titanic_data %>% \n  select(source, passenger_id, survived,  sex, age, fare, pclass, embarked, \n         family_count, pax_in_group, pax_in_ticket_head, groups_in_ticket,\n         final_grouping) %>% \n  mutate(final_grouping = as_factor(final_grouping),\n         survived = as_factor(survived),\n         pclass = as_factor(pclass),\n         sex = as_factor(sex),\n         embarked = as_factor(embarked))\nglimpse(titanic_data2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,309\nColumns: 13\n$ source             <chr> \"train\", \"train\", \"train\", \"train\", \"train\", \"train‚Ä¶\n$ passenger_id       <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ‚Ä¶\n$ survived           <fct> 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, ‚Ä¶\n$ sex                <fct> male, female, female, female, male, male, male, mal‚Ä¶\n$ age                <dbl> 22, 38, 26, 35, 35, 22, 54, 2, 27, 14, 4, 58, 20, 3‚Ä¶\n$ fare               <dbl> 22, 38, 26, 35, 35, 22, 54, 2, 27, 14, 4, 58, 20, 3‚Ä¶\n$ pclass             <fct> 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, ‚Ä¶\n$ embarked           <fct> S, C, S, S, S, Q, S, S, S, C, S, S, S, S, S, S, Q, ‚Ä¶\n$ family_count       <dbl> 2, 2, 1, 2, 1, 1, 1, 5, 3, 2, 3, 1, 1, 7, 1, 1, 6, ‚Ä¶\n$ pax_in_group       <int> 1, 2, 1, 2, 1, 1, 1, 5, 3, 2, 3, 1, 1, 7, 1, 1, 6, ‚Ä¶\n$ pax_in_ticket_head <int> 5, 14, 2, 8, 1, 1, 6, 5, 4, 4, 3, 14, 1, 22, 8, 1, ‚Ä¶\n$ groups_in_ticket   <int> 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ final_grouping     <fct> Braund_A/5 2117, Cumings_PC 1759, Heikkinen_STON/O2‚Ä¶\n```\n:::\n:::\n\n\nNow this is the part I don't get. Why does Kaggle call it `train` and `test` when it can be easily told to be `given_data` and `to_predict` data?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nto_predict <- titanic_data2 %>% \n  filter(source == \"test\") %>% select(-survived, -source)\ngiven_data <- titanic_data2 %>% \n  filter(source == \"train\") %>% select(-source)\n```\n:::\n\n\n`given_data` has all the necessary columns we need to train the algo on\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(given_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 891\nColumns: 12\n$ passenger_id       <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ‚Ä¶\n$ survived           <fct> 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, ‚Ä¶\n$ sex                <fct> male, female, female, female, male, male, male, mal‚Ä¶\n$ age                <dbl> 22, 38, 26, 35, 35, 22, 54, 2, 27, 14, 4, 58, 20, 3‚Ä¶\n$ fare               <dbl> 22, 38, 26, 35, 35, 22, 54, 2, 27, 14, 4, 58, 20, 3‚Ä¶\n$ pclass             <fct> 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, ‚Ä¶\n$ embarked           <fct> S, C, S, S, S, Q, S, S, S, C, S, S, S, S, S, S, Q, ‚Ä¶\n$ family_count       <dbl> 2, 2, 1, 2, 1, 1, 1, 5, 3, 2, 3, 1, 1, 7, 1, 1, 6, ‚Ä¶\n$ pax_in_group       <int> 1, 2, 1, 2, 1, 1, 1, 5, 3, 2, 3, 1, 1, 7, 1, 1, 6, ‚Ä¶\n$ pax_in_ticket_head <int> 5, 14, 2, 8, 1, 1, 6, 5, 4, 4, 3, 14, 1, 22, 8, 1, ‚Ä¶\n$ groups_in_ticket   <int> 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ final_grouping     <fct> Braund_A/5 2117, Cumings_PC 1759, Heikkinen_STON/O2‚Ä¶\n```\n:::\n:::\n\n\n`to_predict` dataframe has everything else except **survived** column that needs to be predicted.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(to_predict)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 418\nColumns: 11\n$ passenger_id       <int> 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 9‚Ä¶\n$ sex                <fct> male, female, male, male, female, male, female, mal‚Ä¶\n$ age                <dbl> 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.‚Ä¶\n$ fare               <dbl> 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.‚Ä¶\n$ pclass             <fct> 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, ‚Ä¶\n$ embarked           <fct> Q, S, Q, S, S, S, Q, S, C, S, S, S, S, S, S, C, Q, ‚Ä¶\n$ family_count       <dbl> 1, 2, 1, 1, 3, 1, 1, 3, 1, 3, 1, 1, 2, 2, 2, 2, 1, ‚Ä¶\n$ pax_in_group       <int> 1, 1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 1, 2, 2, 2, 2, 1, ‚Ä¶\n$ pax_in_ticket_head <int> 3, 1, 1, 6, 11, 3, 3, 6, 16, 4, 10, 3, 2, 2, 2, 4, ‚Ä¶\n$ groups_in_ticket   <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ final_grouping     <fct> Kelly_33091, Wilkes_36327, Myles_24027, Wirz_31515,‚Ä¶\n```\n:::\n:::\n\n\nPhew. finally done with the pre-processing. Thanks for sticking around. Here have a gif\n\n![](https://media.giphy.com/media/lSVXGiITXtabGGxAyg/giphy.gif){fig-align=\"center\" width=\"240\"}\n\n# Model Building\n\nSo today I'm going to be taking different classification models and compare the findings on a 10-fold bootstrap resample. The 4 selected models are:\n\n1.  Logistic classification\n2.  Random Forest\n3.  Support Vector Machines\n4.  Decision Trees\n\nThe [Tidymodels textbook](https://www.tmwr.org/workflows.html#workflow-sets-intro) is possibly the best place to begin understanding about workflow. In a nutshell:\n\n1.  Create resampling folds\n\n2.  Describe each model (I'm going to be using untuned parameters for sake of simplicity)\n\n3.  create a base recipe for `given_data`\n\n4.  Defining a workflow that uses the recipe for each model\n\n5.  Fit the resampled folds on the workflow_set\n\n6.  Find the winning model - since we're dealing with classification, I am using `roc_auc`\n\n7.  fit the winning model to the `given data`\n\n8.  Generate predictions on `to_predict` df using the best fit\n\n9.  submit on kaggle\n\n10. ...\n\n11. profit? (well not exactly. but you can create another blog and share your new found knowledge with the worldü§ì)\n\nSo lets get cooking!\n\n## Step 1: creating resampling folds\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2023)\ntitanic_folds <- bootstraps(data = given_data, \n                            times = 15)\ntitanic_folds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Bootstrap sampling \n# A tibble: 15 √ó 2\n   splits            id         \n   <list>            <chr>      \n 1 <split [891/318]> Bootstrap01\n 2 <split [891/313]> Bootstrap02\n 3 <split [891/340]> Bootstrap03\n 4 <split [891/313]> Bootstrap04\n 5 <split [891/326]> Bootstrap05\n 6 <split [891/342]> Bootstrap06\n 7 <split [891/316]> Bootstrap07\n 8 <split [891/323]> Bootstrap08\n 9 <split [891/338]> Bootstrap09\n10 <split [891/331]> Bootstrap10\n11 <split [891/319]> Bootstrap11\n12 <split [891/322]> Bootstrap12\n13 <split [891/340]> Bootstrap13\n14 <split [891/321]> Bootstrap14\n15 <split [891/320]> Bootstrap15\n```\n:::\n:::\n\n\n## Step 2: Recipe\n\nCreating the `base_recipe` object that has only 3 steps\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_recipe <- recipe(survived ~ ., data = given_data) %>% \n  update_role(passenger_id, new_role = \"id_variable\") %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_normalize(all_numeric_predictors()) \nbase_recipe\n```\n:::\n\n\nOr if one would like to see it in a `tidy` format.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(base_recipe)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 √ó 6\n  number operation type      trained skip  id             \n   <int> <chr>     <chr>     <lgl>   <lgl> <chr>          \n1      1 step      dummy     FALSE   FALSE dummy_FSxXz    \n2      2 step      normalize FALSE   FALSE normalize_bu1Ti\n```\n:::\n:::\n\n\n## Step 3: Model definitions\n\nAll the four models are defined as:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#logistic regression\nglm_model <- logistic_reg() %>% \n  set_engine(\"glm\") %>% \n  set_mode(\"classification\")\n\n#random forest\nrf_model <- rand_forest(trees = 1000) %>% \n  set_engine(\"ranger\") %>% \n  set_mode(\"classification\")\n\n#support vector machines\nsvm_model <- svm_rbf() %>% # rbf - radial based\n  set_engine(\"kernlab\") %>% \n  set_mode(\"classification\")\n\n#decision tree\ndt_model <- decision_tree(mode = \"classification\", \n                          tree_depth = 3) %>% \n  set_engine(\"rpart\")\n```\n:::\n\n\n## Step 4: Workflow set\n\nJust as you would with a single model, the workflow combines the base recipe with the multiple models by using lists when declaring the object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_wf_set <- workflow_set(\n  list(base_recipe),\n  list(glm_model, rf_model, svm_model, dt_model),\n  cross = T\n)\ntitanic_wf_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 4 √ó 4\n  wflow_id             info             option    result    \n  <chr>                <list>           <list>    <list>    \n1 recipe_logistic_reg  <tibble [1 √ó 4]> <opts[0]> <list [0]>\n2 recipe_rand_forest   <tibble [1 √ó 4]> <opts[0]> <list [0]>\n3 recipe_svm_rbf       <tibble [1 √ó 4]> <opts[0]> <list [0]>\n4 recipe_decision_tree <tibble [1 √ó 4]> <opts[0]> <list [0]>\n```\n:::\n:::\n\n\nIn the table above, the **result** column shows a list\\[0\\] implying that it is currently empty. This is because till now, we've only defined the workflows and models but are yet to pass the data though it.\n\nObligatory shout out to the phenom Julia Silge whose YT tutorials and blogs have been my learning books at each step. These steps are succinctly explained in her [Tidy Tuesday post](https://juliasilge.com/blog/giant-pumpkins/) which I highly recommend.\n\n## Step 5: Fitting on resampled folds\n\nSo this part of it needs to be dealt with care. Resampling may take a while...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\nset.seed(2023)\ndoParallel::registerDoParallel()\ntitanic_rs <- workflow_map(\n  titanic_wf_set,\n  \"fit_resamples\",\n  resamples = titanic_folds\n)\nend_time <- Sys.time()\n```\n:::\n\n\n... which is ...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nend_time - start_time\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 11.58433 mins\n```\n:::\n:::\n\n\nHmm... So moving on. What does the workflow_set object look like now?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 4 √ó 4\n  wflow_id             info             option    result   \n  <chr>                <list>           <list>    <list>   \n1 recipe_logistic_reg  <tibble [1 √ó 4]> <opts[1]> <rsmp[+]>\n2 recipe_rand_forest   <tibble [1 √ó 4]> <opts[1]> <rsmp[+]>\n3 recipe_svm_rbf       <tibble [1 √ó 4]> <opts[1]> <rsmp[+]>\n4 recipe_decision_tree <tibble [1 √ó 4]> <opts[1]> <rsmp[+]>\n```\n:::\n:::\n\n\n## Step 6: Finding the winning model\n\nThis is how the `tidymodels` package all fits in. If you've got all the steps covered this far, the decision making shouldn't take much effort\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(titanic_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 √ó 9\n  wflow_id             .config preproc model .metric .esti‚Ä¶¬π  mean     n std_err\n  <chr>                <chr>   <chr>   <chr> <chr>   <chr>   <dbl> <int>   <dbl>\n1 recipe_logistic_reg  Prepro‚Ä¶ recipe  logi‚Ä¶ accura‚Ä¶ binary  0.675    15 0.0147 \n2 recipe_logistic_reg  Prepro‚Ä¶ recipe  logi‚Ä¶ roc_auc binary  0.695    15 0.0184 \n3 recipe_rand_forest   Prepro‚Ä¶ recipe  rand‚Ä¶ accura‚Ä¶ binary  0.824    15 0.00484\n4 recipe_rand_forest   Prepro‚Ä¶ recipe  rand‚Ä¶ roc_auc binary  0.872    15 0.00488\n5 recipe_svm_rbf       Prepro‚Ä¶ recipe  svm_‚Ä¶ accura‚Ä¶ binary  0.780    15 0.00706\n6 recipe_svm_rbf       Prepro‚Ä¶ recipe  svm_‚Ä¶ roc_auc binary  0.806    15 0.00704\n7 recipe_decision_tree Prepro‚Ä¶ recipe  deci‚Ä¶ accura‚Ä¶ binary  0.809    15 0.00476\n8 recipe_decision_tree Prepro‚Ä¶ recipe  deci‚Ä¶ roc_auc binary  0.811    15 0.00684\n# ‚Ä¶ with abbreviated variable name ¬π‚Äã.estimator\n```\n:::\n:::\n\n\nSince we're looking at classification, lets see which one of the models resulted in the best `roc_auc`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(titanic_rs) %>% \n  filter(.metric == \"roc_auc\") %>% \n  arrange(desc(mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 √ó 9\n  wflow_id             .config preproc model .metric .esti‚Ä¶¬π  mean     n std_err\n  <chr>                <chr>   <chr>   <chr> <chr>   <chr>   <dbl> <int>   <dbl>\n1 recipe_rand_forest   Prepro‚Ä¶ recipe  rand‚Ä¶ roc_auc binary  0.872    15 0.00488\n2 recipe_decision_tree Prepro‚Ä¶ recipe  deci‚Ä¶ roc_auc binary  0.811    15 0.00684\n3 recipe_svm_rbf       Prepro‚Ä¶ recipe  svm_‚Ä¶ roc_auc binary  0.806    15 0.00704\n4 recipe_logistic_reg  Prepro‚Ä¶ recipe  logi‚Ä¶ roc_auc binary  0.695    15 0.0184 \n# ‚Ä¶ with abbreviated variable name ¬π‚Äã.estimator\n```\n:::\n:::\n\n\nLooks like the `rand_forest` is the winner!\n\n![](https://media.giphy.com/media/dZLx6Lf738Jy46tUR4/giphy.gif){width=\"360\"}\n\nAnother wonderful way it all ties in together is the visualisation with a single line of code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(titanic_rs)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\nPieces of code that just fit into each other feels like a spoon-full of ice cream!\n\n## Step 7 & 8: Fitting the winner and predictions\n\nFrom the object `titanic_rs` we need to pick the winning model and fit to `to_predict`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <- extract_workflow(titanic_rs, \n                              \"recipe_rand_forest\") %>% \n  fit(given_data)\n\nfinal_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: rand_forest()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 Recipe Steps\n\n‚Ä¢ step_dummy()\n‚Ä¢ step_normalize()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  1000 \nSample size:                      891 \nNumber of independent variables:  908 \nMtry:                             30 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1386875 \n```\n:::\n:::\n\n\nCreating a new dataframe for predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_predictions <- predict(object = final_fit, \n                             new_data = to_predict)\n\nfinal_predictions <- final_predictions %>% \n  rename(Survived = .pred_class) %>% \n  bind_cols(PassengerId = to_predict$passenger_id)\nhead(final_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 √ó 2\n  Survived PassengerId\n  <fct>          <int>\n1 0                892\n2 0                893\n3 0                894\n4 0                895\n5 0                896\n6 0                897\n```\n:::\n:::\n\n\n## Step 9: Submit to Kaggle\n\nConverting the `final_predictions` to csv and uploading to kaggle\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(final_predictions, row.names = F, \n          file = \"submissions.csv\")\n```\n:::\n\n\nUploaded it to Kaggle and behold...\n\n![](images/image-1373401355.png){fig-align=\"center\"}\n\nNot bad !!! that's like top 12% percentile.\n\n![.. And so did you, dear reader!!](https://media.giphy.com/media/7zYKTVt3vvbj7SC2Bl/giphy.gif){fig-align=\"center\" width=\"50%\"}\n\n# Tailpiece regarding `autoplot()`\n\nAfter model creation, I couldn't help wonder at the marvel behind the `autoplot()` function. How can a single function decipher convey such meaningful depth?\n\n## Peeking under the hood\n\nI tried to replicate the same errorbar plot generated by the function. For me, this was possibly one of the bigger conceptual lessons about `tidymodels` framework. Here's how I did it:\n\nThere are 15 bootsample folds that were generated. The `workflow_set` maps the `fit_resamples` function on the workflow. This implies that each of the 4 models have generated 2 pairs of metrics (`accuracy` & `roc_auc`) for each of the 15 resamples.\n\nThe `collect_metrics` function generates the mean vale of each metric allowing us to chose the best one.\n\nThe manner in which all of this is done within a single object is sublime. Information is stored in tibbles within tibbles!\n\nFor instance, let us look at the class of `titanic_rs`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(titanic_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"workflow_set\" \"tbl_df\"       \"tbl\"          \"data.frame\"  \n```\n:::\n:::\n\n\nIt is a tibble with 4 columns out of which `results` is a list object consisting of more tibbles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A workflow set/tibble: 4 √ó 4\n  wflow_id             info             option    result   \n  <chr>                <list>           <list>    <list>   \n1 recipe_logistic_reg  <tibble [1 √ó 4]> <opts[1]> <rsmp[+]>\n2 recipe_rand_forest   <tibble [1 √ó 4]> <opts[1]> <rsmp[+]>\n3 recipe_svm_rbf       <tibble [1 √ó 4]> <opts[1]> <rsmp[+]>\n4 recipe_decision_tree <tibble [1 √ó 4]> <opts[1]> <rsmp[+]>\n```\n:::\n:::\n\n\nWhat does the first tibble in the `results` list look like? This corresponds to the logistic regression model as shown in the table above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_rs$result[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Bootstrap sampling \n# A tibble: 15 √ó 4\n   splits            id          .metrics         .notes          \n   <list>            <chr>       <list>           <list>          \n 1 <split [891/318]> Bootstrap01 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n 2 <split [891/313]> Bootstrap02 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n 3 <split [891/340]> Bootstrap03 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n 4 <split [891/313]> Bootstrap04 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n 5 <split [891/326]> Bootstrap05 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n 6 <split [891/342]> Bootstrap06 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n 7 <split [891/316]> Bootstrap07 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n 8 <split [891/323]> Bootstrap08 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n 9 <split [891/338]> Bootstrap09 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n10 <split [891/331]> Bootstrap10 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n11 <split [891/319]> Bootstrap11 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n12 <split [891/322]> Bootstrap12 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n13 <split [891/340]> Bootstrap13 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n14 <split [891/321]> Bootstrap14 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n15 <split [891/320]> Bootstrap15 <tibble [2 √ó 4]> <tibble [3 √ó 3]>\n\nThere were issues with some computations:\n\n  - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x1: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x4: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x11: Column(s) have zero variance so scaling cannot be used: `final_gr...   - Warning(s) x15: Column(s) have zero variance so scaling cannot be used: `final_gr...\n\nRun `show_notes(.Last.tune.result)` for more information.\n```\n:::\n:::\n\n\nWhat does the `.metrics` list contain?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic_rs$result[[1]]$.metrics[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 √ó 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.682 Preprocessor1_Model1\n2 roc_auc  binary         0.655 Preprocessor1_Model1\n```\n:::\n:::\n\n\nSo `.metrics` is a list of results that is generated for each of the folds. The above tibble is the resulting metrics after cross-validation of the first fold of `titanic_folds` using `glm` (logisitic classification).\n\nIf the intent is to create the errorgraph manually, then we'll need to extract the data within each of these tibbles.\n\nNow I wasn't able to check the code for `autoplot()` and I'm pretty certain there's a more elegant method out there. Hit me up if you feel there's a better way to extract data from within tibbles in the comments here üëâüèº\n\nFirst step is to create an empty tibble consisting of 4 models, 2 metrics and 80 empty cells that need to be filled in from `titanic_rs` object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_titanic_rs <- tibble(wf = rep(unique(titanic_rs$wflow_id), 15*2),\n                          metrics = rep(c(rep(\"accuracy\", 4), \n                                          rep(\"roc_auc\",4)),\n                                        15),\n                          values = rep(NA, 4*15*2))\nhead(tidy_titanic_rs, 8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 √ó 3\n  wf                   metrics  values\n  <chr>                <chr>    <lgl> \n1 recipe_logistic_reg  accuracy NA    \n2 recipe_rand_forest   accuracy NA    \n3 recipe_svm_rbf       accuracy NA    \n4 recipe_decision_tree accuracy NA    \n5 recipe_logistic_reg  roc_auc  NA    \n6 recipe_rand_forest   roc_auc  NA    \n7 recipe_svm_rbf       roc_auc  NA    \n8 recipe_decision_tree roc_auc  NA    \n```\n:::\n:::\n\n\nDimensions of this empty table?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(tidy_titanic_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 120   3\n```\n:::\n:::\n\n\nTo extract the values from the tibbles in `titanic_rs` and save in `tidy_titanic_rs`, I proceeded to employ a nested `for` loop. Dont' judge, i say!\n\n## Extracting the tibbles\n\n`pluck` has got to be the coolest function I've ever come across!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbigtable <- purrr:::pluck(titanic_rs, 4)\nwflow_id_titanic <- unique(titanic_rs$wflow_id)\nfor(i in 1:length(wflow_id_titanic)){\n    \n  wflow_id <- wflow_id_titanic[i]\n  smalltable <- bigtable[[i]]\n  \n  for(j in 1:length(smalltable$.metrics)){\n    smallertable <- purrr::pluck(smalltable$.metrics, j)\n    tidy_titanic_rs$values[(tidy_titanic_rs$wf==wflow_id & \n                              tidy_titanic_rs$metrics==\"accuracy\")][j] <- smallertable$.estimate[smallertable$.metric == \"accuracy\"]\n    tidy_titanic_rs$values[(tidy_titanic_rs$wf==wflow_id & \n                              tidy_titanic_rs$metrics==\"roc_auc\")][j] <- smallertable$.estimate[smallertable$.metric == \"roc_auc\"]\n    \n  }\n}\n\ntidy_titanic_rs2 <- tidy_titanic_rs %>% \n  group_by(wf, metrics) %>% \n  summarise(value_min = mean(values) - 0.5*sd(values),\n            value_max = mean(values) + 0.5*sd(values),\n            value_mean = mean(values)) %>% ungroup() %>% \n  right_join(tidy_titanic_rs, by = c(\"wf\", \"metrics\"))\n```\n:::\n\n\nFor some reason, `value_max` and `value_min` for the error-bar are 0.5 \\* ùùà or approximately [¬±19% of the mean of values](https://mathbitsnotebook.com/Algebra2/Statistics/STstandardNormalDistribution.html#:~:text=Reading%20from%20the%20chart%2C%20it,or%20left)%20of%20the%20mean.)\n\n## Manually generated plot\n\nWith the data in a rectangular tidy format, the rest of the magic is handled by `ggplot`\n\n***cracks knuckles***\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_titanic_rs2 %>% \nggplot(aes(x = reorder(wf, desc(value_mean)), \n             y = values, \n             color = wf))+\n  geom_errorbar(aes(ymax = value_max, ymin = value_min), \n                width = 0.1)+\n  geom_point(aes(y= value_mean))+\n  scale_y_continuous(breaks = seq(0.65, 0.9, 0.05),\n                     limits = c(0.65, 0.9))+\n  theme(legend.position = \"none\")+\n  labs(x = NULL, y = NULL)+\n  facet_wrap(~metrics)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\nAnd here once again is the auto-generated plot. Not bad, eh?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(titanic_rs)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\n![Oooh yeeah!](https://media.giphy.com/media/3oEduKVQdG4c0JVPSo/giphy.gif){fig-align=\"center\" width=\"50%\"}\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}