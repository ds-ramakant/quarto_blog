---
title: "Day 11 of #50daysofkaggle"
subtitle: "Roadmap to tidymodels"
description: "Titanic dataset in R"
date: '2023-02-20'
categories: [kaggle, R]
featured: no
image: titanic.jpg
---

Till now I practiced creating classification predictions on the Titanic dataset using KNN, DT and SVM algorithms. As per Kaggle, [my submission got a score of 77%](https://www.kaggle.com/code/dsramakant/titanic-classification-by-decision-trees-python). Now I'm going to try these approaches in R.

steps to do : data reading \> cleaning \> replacing NA \> splitting \> model using Decision Trees\> comparing results

# Data reading and cleaning

```{r}
library(tidyverse)
library(zip)
library(readr)
library(tidymodels)

#reading kaggle zip file that I downloaded in older folder
ziplocation <- "D:/Ramakant/Personal/Weekends in Mumbai/Blog/quarto_blog/posts/2022-10-12-day-6-of-50daysofkaggle/titanic.zip"
df <-  read_csv(unz(ziplocation, "train.csv"))
df %>% head()

#selecting numerical features and removing PassengerID & Survived

glimpse(df)
df_n <- df %>% 
  select_if(is.numeric) %>% 
  select(-PassengerId)

df_n <- df_n %>% 
  bind_cols(Sex = df$Sex, Embarked = df$Embarked) 
glimpse(df)

#finding null values

df_n$Survived <- as.factor(df_n$Survived)

df_n %>%  
  summarise_all(~ sum(is.na(.)))
```

Finding the mean of `Age` values and replacing NA values in `Age`

```{r}
median(df_n$Age, na.rm = T)

df_n <- df_n %>% 
  mutate(Age = replace_na(Age, median(Age, na.rm = T)))

df_n %>% summarise_all(~sum(is.na(.)))
```

# Model Building

Splitting the data into train & test

```{r}
df_split <- initial_split(df_n, prop = 0.8)
train <- training(df_split)
test <- testing(df_split)

df_split
```

creating the recipe

```{r}
show_engines("decision_tree") #shows the list of engines & modes
```

```{r}
dt_recipe <- recipe(Survived ~ ., data = df_n) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  #replacing NA values in Age with median Age
  step_mutate_at(Age, fn = ~ replace_na(Age, median(Age, na.rm = T))) 
  # %>% step_mutate_at(Survived, fn = ~as_factor(Survived))

dt_recipe
tidy(dt_recipe)


dt_model <- decision_tree(mode = "classification", tree_depth = 3) %>% 
  set_engine("rpart")

dt_model %>% translate()
```

Creating a workflow based on the model \> fitting data \> predicting the results

```{r}

dt_wf <- workflow() %>%
  add_model(dt_model) %>% 
  add_recipe(dt_recipe)


dt_predict <- predict(fit(dt_wf, data = train), test)

test_n <- bind_cols(test, dt_predict)
test_n <- test_n %>% 
  rename(dt_yhat = .pred_class)

predicted_table <- test_n %>% 
  select(Survived, dt_yhat) 

#this table converts factors to numeric values
predicted_table2 <- test_n %>% 
  select(Survived, dt_yhat) %>% 
#convert factor to numeric
 mutate(across(where(is.factor), as.numeric)) %>%
#conversion takes values 1 & 2 instead of 0 & 1, hence correcting back
 mutate(across(1:2, ~.x -1))

predicted_table2 %>% rmse(dt_yhat, Survived)

```

# Testing accuracy

As mentioned in the [TMRW documentation for binary classification metrics](https://www.tmwr.org/performance.html#binary-classification-metrics), we will try creating the confusion matrix and checking accuracy

```{r}
predicted_table

conf_mat(predicted_table, truth = Survived, estimate = dt_yhat)
```

```{r}
accuracy(predicted_table, truth = Survived, estimate = dt_yhat)


```

```{r}

classification_metrics <- metric_set(accuracy, f_meas)

predicted_table %>% 
  classification_metrics(truth = Survived, estimate = dt_yhat)
```
